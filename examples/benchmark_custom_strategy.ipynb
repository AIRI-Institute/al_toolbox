{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "568fa282-0a1d-4568-ab7f-8112c7a110d4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## How to add new AL query strategies / unlabeled pool subsampling strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90492c44-fc55-48e5-b416-46d07569f6ce",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This notebook demonstrates three simple steps to benchmark a new query / unlabeled pool subsampling strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457a08c5-f9fc-42de-be73-02dbd2d01364",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1. Prepare the file and the global variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb948181-644a-43a0-9e63-5283d26cbf5a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘custom_strategy’: File exists\n"
     ]
    }
   ],
   "source": [
    "# Where the file with the strategy is located\n",
    "FOLDER_WITH_STRATEGIES = \"custom_strategy\"\n",
    "!mkdir $FOLDER_WITH_STRATEGIES\n",
    "# Name of the AL strategy & file\n",
    "AL_STRATEGY_NAME = \"least_confidence.py\"\n",
    "# Name of the unlabeled pool subsampling strategy addition\n",
    "SUBSAMPLING_STRATEGY_NAME = \"top_from_previous_iteration_subsampling.py\"\n",
    "CUR_PATH = !pwd\n",
    "# Absolute path to the AL strategy\n",
    "PATH_TO_AL_STRATEGY = f\"{CUR_PATH[0]}/{FOLDER_WITH_STRATEGIES}/{AL_STRATEGY_NAME}\"\n",
    "# Absolute path to the strategy\n",
    "PATH_TO_SUBSAMPLING_STRATEGY = (\n",
    "    f\"{CUR_PATH[0]}/{FOLDER_WITH_STRATEGIES}/{SUBSAMPLING_STRATEGY_NAME}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43852b4-381c-4063-a342-50e10f4803da",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 2. Write your strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53dc392e-9628-4e91-999f-057d6670cafd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/atsvigun/active_learning/examples/custom_strategy/least_confidence.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $PATH_TO_AL_STRATEGY\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def least_confidence(model, X_pool, n_instances, **kwargs):\n",
    "    probas = model.predict_proba(X_pool)\n",
    "    uncertainty_estimates = 1 - probas.max(axis=1)\n",
    "    query_idx = np.argsort(-uncertainty_estimates)[:n_instances]\n",
    "    query = X_pool.select(query_idx)\n",
    "    return query_idx, query, uncertainty_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "212ca7da-795b-47c7-80a1-e92407b78ca1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/atsvigun/active_learning/examples/custom_strategy/top_from_previous_iteration_subsampling.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $PATH_TO_SUBSAMPLING_STRATEGY\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def top_from_previous_iteration_subsampling(uncertainty_estimates, gamma_or_k_confident_to_save, **kwargs):\n",
    "    if isinstance(gamma_or_k_confident_to_save, float):\n",
    "        gamma_or_k_confident_to_save = int(\n",
    "            gamma_or_k_confident_to_save * len(uncertainty_estimates)\n",
    "        )\n",
    "    argsort = np.argsort(-uncertainty_estimates)\n",
    "    return argsort[:gamma_or_k_confident_to_save]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d6a580-3f60-4a11-8137-99f58723b867",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 3. Use your strategies:\n",
    "\n",
    "- AL strategy: `config.al.strategy=$PATH_TO_AL_STRATEGY`\n",
    "\n",
    "- Unlabeled pool subsampling strategy: `config.al.sampling_type=$PATH_TO_SUBSAMPLING_STRATEGY`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012a9bbc-3d40-4b43-a7f8-565eb85b9d9e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Test with 1 GPU: (substitute `custom_strategy/least_confidence` & `custom_strategy/top_from_previous_iteration_subsampling` with your strategies name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f45045b6-e72a-4cfc-bbf7-8a8c6ba43756",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-14 14:10:22,670][root][INFO] - Work dir: /home/atsvigun/active_learning/examples/workdir/run_active_learning/2022-09-14/14-10-22_42_roberta_base_custom_strategy_least_confidence\n",
      "[2022-09-14 14:10:39,668][root][INFO] - Successfully loaded BARTScore and SummaC models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atsvigun/anaconda3/envs/al/lib/python3.9/site-packages/transformers/image_utils.py:222: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  def resize(self, image, size, resample=PIL.Image.BILINEAR, default_to_square=True, max_size=None):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-14 14:10:41,245][root][INFO] - output_dir: ./workdir/run_active_learning\n",
      "[2022-09-14 14:10:41,245][root][INFO] - seed: 42\n",
      "[2022-09-14 14:10:41,245][root][INFO] - cuda_device: 0\n",
      "[2022-09-14 14:10:41,245][root][INFO] - cache_dir: ././workdir/run_active_learning/cache_42_roberta_base\n",
      "[2022-09-14 14:10:41,245][root][INFO] - cache_model_and_dataset: False\n",
      "[2022-09-14 14:10:41,246][root][INFO] - framework: transformers\n",
      "[2022-09-14 14:10:41,246][root][INFO] - task: cls\n",
      "[2022-09-14 14:10:41,246][root][INFO] - offline_mode: False\n",
      "[2022-09-14 14:10:41,246][root][INFO] - data\n",
      "[2022-09-14 14:10:41,246][root][INFO] - \tdataset_name: ag_news\n",
      "[2022-09-14 14:10:41,246][root][INFO] - \ttext_name: text\n",
      "[2022-09-14 14:10:41,246][root][INFO] - \tlabel_name: label\n",
      "[2022-09-14 14:10:41,246][root][INFO] - \tlabels_to_remove: None\n",
      "[2022-09-14 14:10:41,246][root][INFO] - \tpath: datasets\n",
      "[2022-09-14 14:10:41,246][root][INFO] - \ttrain_size_split: 0.9\n",
      "[2022-09-14 14:10:41,247][root][INFO] - \tseed: 42\n",
      "[2022-09-14 14:10:41,247][root][INFO] - acquisition_model\n",
      "[2022-09-14 14:10:41,260][root][INFO] - \ttype: cls\n",
      "[2022-09-14 14:10:41,260][root][INFO] - \tcheckpoint: roberta-base\n",
      "[2022-09-14 14:10:41,260][root][INFO] - \ttokenizer_max_length: 256\n",
      "[2022-09-14 14:10:41,260][root][INFO] - \tnum_labels: None\n",
      "[2022-09-14 14:10:41,261][root][INFO] - \tclassifier_dropout: 0.0\n",
      "[2022-09-14 14:10:41,262][root][INFO] - \texists_in_repo: True\n",
      "[2022-09-14 14:10:41,262][root][INFO] - \tpath_to_pretrained: None\n",
      "[2022-09-14 14:10:41,262][root][INFO] - \ttraining\n",
      "[2022-09-14 14:10:41,262][root][INFO] - \t\tdev_size: 0.0\n",
      "[2022-09-14 14:10:41,262][root][INFO] - \t\tshuffle_dev: False\n",
      "[2022-09-14 14:10:41,262][root][INFO] - \t\tfreeze_embedder: False\n",
      "[2022-09-14 14:10:41,262][root][INFO] - \t\tbatch_size_args\n",
      "[2022-09-14 14:10:41,263][root][INFO] - \t\t\tbatch_size: 16\n",
      "[2022-09-14 14:10:41,264][root][INFO] - \t\t\teval_batch_size: 100\n",
      "[2022-09-14 14:10:41,264][root][INFO] - \t\t\tmin_num_gradient_steps: 350\n",
      "[2022-09-14 14:10:41,264][root][INFO] - \t\t\tadjust_batch_size: True\n",
      "[2022-09-14 14:10:41,264][root][INFO] - \t\t\tadjust_num_epochs: True\n",
      "[2022-09-14 14:10:41,264][root][INFO] - \t\t\tmin_batch_size: 4\n",
      "[2022-09-14 14:10:41,268][root][INFO] - \t\ttrainer_args\n",
      "[2022-09-14 14:10:41,268][root][INFO] - \t\t\tnum_epochs: 10\n",
      "[2022-09-14 14:10:41,268][root][INFO] - \t\t\tpatience: 1000\n",
      "[2022-09-14 14:10:41,268][root][INFO] - \t\t\tgrad_clipping: 1.0\n",
      "[2022-09-14 14:10:41,268][root][INFO] - \t\t\tserialization_dir: ./output/roberta_base_42_2022-09-14_14-10-22/acquisition\n",
      "[2022-09-14 14:10:41,268][root][INFO] - \t\t\tvalidation_metric: accuracy\n",
      "[2022-09-14 14:10:41,268][root][INFO] - \t\t\tevaluation_strategy: no\n",
      "[2022-09-14 14:10:41,268][root][INFO] - \t\t\teval_metrics: ['f1']\n",
      "[2022-09-14 14:10:41,269][root][INFO] - \t\t\tfp16\n",
      "[2022-09-14 14:10:41,269][root][INFO] - \t\t\t\ttraining: True\n",
      "[2022-09-14 14:10:41,269][root][INFO] - \t\t\t\tevaluation: False\n",
      "[2022-09-14 14:10:41,269][root][INFO] - \t\t\taccumulation\n",
      "[2022-09-14 14:10:41,269][root][INFO] - \t\t\t\tgradient_accumulation_steps: 1\n",
      "[2022-09-14 14:10:41,269][root][INFO] - \t\t\t\teval_accumulation_steps: None\n",
      "[2022-09-14 14:10:41,269][root][INFO] - \t\toptimizer_args\n",
      "[2022-09-14 14:10:41,269][root][INFO] - \t\t\tweight_decay: 0.01\n",
      "[2022-09-14 14:10:41,269][root][INFO] - \t\t\tlr: 2e-05\n",
      "[2022-09-14 14:10:41,270][root][INFO] - \t\tscheduler_args\n",
      "[2022-09-14 14:10:41,270][root][INFO] - \t\t\twarmup_steps_factor: 0.1\n",
      "[2022-09-14 14:10:41,270][root][INFO] - \t\t\tuse_adafactor: False\n",
      "[2022-09-14 14:10:41,270][root][INFO] - successor_model: None\n",
      "[2022-09-14 14:10:41,270][root][INFO] - al\n",
      "[2022-09-14 14:10:41,270][root][INFO] - \tstrategy: custom_strategy/least_confidence\n",
      "[2022-09-14 14:10:41,270][root][INFO] - \tnum_queries: 15\n",
      "[2022-09-14 14:10:41,270][root][INFO] - \tinit_p_or_n: 0.01\n",
      "[2022-09-14 14:10:41,271][root][INFO] - \tstep_p_or_n: 0.01\n",
      "[2022-09-14 14:10:41,272][root][INFO] - \tgamma_or_k_confident_to_save: 0.25\n",
      "[2022-09-14 14:10:41,272][root][INFO] - \tT: 0.1\n",
      "[2022-09-14 14:10:41,272][root][INFO] - \tsampling_type: custom_strategy/top_from_previous_iteration_subsampling\n",
      "[2022-09-14 14:10:41,272][root][INFO] - \titers_to_recalc_scores: [0, 1, 4, 8]\n",
      "[2022-09-14 14:10:41,272][root][INFO] - \tevaluate_query: True\n",
      "[2022-09-14 14:10:41,272][root][INFO] - \tstrategy_kwargs\n",
      "[2022-09-14 14:10:41,272][root][INFO] - \t\tmahalanobis_use_da: False\n",
      "[2022-09-14 14:10:41,272][root][INFO] - \t\tmahalanobis_use_v2: False\n",
      "[2022-09-14 14:10:41,273][root][INFO] - \t\tmc_iterations: 10\n",
      "[2022-09-14 14:10:41,273][root][INFO] - \t\tmax_num_samples: 1000\n",
      "[2022-09-14 14:10:41,273][root][INFO] - \t\tonly_head_dropout: False\n",
      "[2022-09-14 14:10:41,273][root][INFO] - \t\tuse_stable_dropout: True\n",
      "[2022-09-14 14:10:41,274][root][INFO] - \t\tn_clusters: 12000\n",
      "[2022-09-14 14:10:41,274][root][INFO] - \t\tinstances_multiplier: 1.25\n",
      "[2022-09-14 14:10:41,274][root][INFO] - \t\trandom_query: True\n",
      "[2022-09-14 14:10:41,274][root][INFO] - \t\tfast: False\n",
      "[2022-09-14 14:10:41,274][root][INFO] - \t\tdistance: cosine\n",
      "[2022-09-14 14:10:41,274][root][INFO] - \t\tmahalanobis_triplet_lamb: 0.25\n",
      "[2022-09-14 14:10:41,275][root][INFO] - \t\tmahalanobis_batched: False\n",
      "[2022-09-14 14:10:41,276][root][INFO] - Loading data...\n",
      "[2022-09-14 14:10:47,345][datasets.builder][WARNING] - Using custom data configuration default\n",
      "[2022-09-14 14:10:47,415][datasets.builder][WARNING] - Reusing dataset ag_news (/home/atsvigun/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 11.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-14 14:10:47,664][root][INFO] - Loaded train size: 120000\n",
      "[2022-09-14 14:10:47,665][root][INFO] - Loaded dev size: 7600\n",
      "[2022-09-14 14:10:47,665][root][INFO] - Dev dataset coincides with test dataset\n",
      "[2022-09-14 14:10:48,033][root][INFO] - Seeding dataset size: 1200\n",
      "[2022-09-14 14:10:48,033][root][INFO] - Pool size: 118800\n",
      "[2022-09-14 14:10:48,039][root][INFO] - Done.\n",
      "[2022-09-14 14:10:48,040][root][INFO] - Starting active learning...\n",
      "[2022-09-14 14:10:48,053][root][INFO] - Constructing the acquisition model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /home/atsvigun/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/vocab.json from cache at /home/atsvigun/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/merges.txt from cache at /home/atsvigun/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer.json from cache at /home/atsvigun/.cache/huggingface/transformers/d53fc0fa09b8342651efd4073d75e19617b3e51287c2a535becda5808a8db287.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /home/atsvigun/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "100%|██████████| 8/8 [00:01<00:00,  4.81ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-14 14:10:57,070][root][INFO] - Done with constructing the acquisition model.\n",
      "[2022-09-14 14:10:57,086][root][INFO] - Training dataset size: 1200\n",
      "[2022-09-14 14:10:57,086][root][INFO] - Validation dataset size: 7600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /home/atsvigun/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"World\",\n",
      "    \"1\": \"Sports\",\n",
      "    \"2\": \"Business\",\n",
      "    \"3\": \"Sci/Tech\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"Business\": 2,\n",
      "    \"Sci/Tech\": 3,\n",
      "    \"Sports\": 1,\n",
      "    \"World\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/roberta-base/resolve/main/pytorch_model.bin from cache at /home/atsvigun/.cache/huggingface/transformers/51ba668f7ff34e7cdfa9561e8361747738113878850a7d717dbc69de8683aaad.c7efaa30a0d80b2958b876969faa180e485944a849deee4ad482332de65365a7\n",
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /home/atsvigun/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/vocab.json from cache at /home/atsvigun/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/merges.txt from cache at /home/atsvigun/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer.json from cache at /home/atsvigun/.cache/huggingface/transformers/d53fc0fa09b8342651efd4073d75e19617b3e51287c2a535becda5808a8db287.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /home/atsvigun/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "100%|██████████| 2/2 [00:00<00:00,  4.69ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-14 14:11:06,499][root][INFO] - Load best at end: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-14 14:11:06,509][root][INFO] - TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=True,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=True,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=40,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./output/roberta_base_42_2022-09-14_14-10-22/acquisition/runs/Sep14_14-11-06_cn-012,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=no,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=eval_accuracy,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=10,\n",
      "optim=adamw_hf,\n",
      "output_dir=./output/roberta_base_42_2022-09-14_14-10-22/acquisition,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=100,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./output/roberta_base_42_2022-09-14_14-10-22/acquisition,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.1,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.01,\n",
      "xpu_backend=None,\n",
      ")\n",
      "[2022-09-14 14:11:17,473][root][INFO] - Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atsvigun/anaconda3/envs/al/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-14 14:12:44,663][root][INFO] - Done with the model fit.\n",
      "[2022-09-14 14:12:44,675][root][INFO] - ############### Evaluating the acquisition model. ###############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00,  9.19ba/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-14 14:12:52,906][root][INFO] - Initial AL iteration:\n",
      "Acquisition model:\n",
      "[2022-09-14 14:12:52,908][root][INFO] - test_loss: 0.5857174396514893\n",
      "[2022-09-14 14:12:52,908][root][INFO] - test_accuracy: 0.8980263157894737\n",
      "[2022-09-14 14:12:52,908][root][INFO] - test_f1_micro: 0.8980263157894738\n",
      "[2022-09-14 14:12:52,908][root][INFO] - test_f1_macro: 0.8975508243070751\n",
      "[2022-09-14 14:12:52,908][root][INFO] - test_f1_weighted: 0.897550824307075\n",
      "[2022-09-14 14:12:52,908][root][INFO] - test_runtime: 7.1048\n",
      "[2022-09-14 14:12:52,908][root][INFO] - test_samples_per_second: 1069.696\n",
      "[2022-09-14 14:12:52,909][root][INFO] - test_steps_per_second: 10.697\n",
      "[2022-09-14 14:12:52,929][root][INFO] - =================AL iteration #1 started.=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AL queries done:   0%|          | 0/15 [00:00<?, ?it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?ba/s]\u001b[A\n",
      "  1%|          | 1/119 [00:00<00:18,  6.31ba/s]\u001b[A\n",
      "  2%|▏         | 2/119 [00:00<00:16,  7.15ba/s]\u001b[A\n",
      "  3%|▎         | 3/119 [00:00<00:15,  7.70ba/s]\u001b[A\n",
      "  3%|▎         | 4/119 [00:00<00:14,  7.86ba/s]\u001b[A\n",
      "  4%|▍         | 5/119 [00:00<00:14,  7.66ba/s]\u001b[A\n",
      "  5%|▌         | 6/119 [00:00<00:14,  7.97ba/s]\u001b[A\n",
      "  6%|▌         | 7/119 [00:00<00:13,  8.26ba/s]\u001b[A\n",
      "  7%|▋         | 8/119 [00:01<00:13,  8.43ba/s]\u001b[A\n",
      "  8%|▊         | 9/119 [00:01<00:12,  8.50ba/s]\u001b[A\n",
      "  8%|▊         | 10/119 [00:01<00:12,  8.59ba/s]\u001b[A\n",
      "  9%|▉         | 11/119 [00:01<00:12,  8.72ba/s]\u001b[A\n",
      " 10%|█         | 12/119 [00:01<00:12,  8.79ba/s]\u001b[A\n",
      " 11%|█         | 13/119 [00:01<00:11,  8.91ba/s]\u001b[A\n",
      " 12%|█▏        | 14/119 [00:01<00:11,  8.95ba/s]\u001b[A\n",
      " 13%|█▎        | 15/119 [00:01<00:11,  8.91ba/s]\u001b[A\n",
      " 13%|█▎        | 16/119 [00:01<00:11,  9.00ba/s]\u001b[A\n",
      " 14%|█▍        | 17/119 [00:02<00:11,  8.89ba/s]\u001b[A\n",
      " 15%|█▌        | 18/119 [00:02<00:11,  8.94ba/s]\u001b[A\n",
      " 16%|█▌        | 19/119 [00:02<00:11,  8.84ba/s]\u001b[A\n",
      " 17%|█▋        | 20/119 [00:02<00:11,  8.86ba/s]\u001b[A\n",
      " 18%|█▊        | 21/119 [00:02<00:11,  8.89ba/s]\u001b[A\n",
      " 18%|█▊        | 22/119 [00:02<00:10,  8.97ba/s]\u001b[A\n",
      " 19%|█▉        | 23/119 [00:02<00:10,  8.99ba/s]\u001b[A\n",
      " 20%|██        | 24/119 [00:02<00:10,  8.96ba/s]\u001b[A\n",
      " 21%|██        | 25/119 [00:02<00:10,  8.92ba/s]\u001b[A\n",
      " 22%|██▏       | 26/119 [00:03<00:14,  6.29ba/s]\u001b[A\n",
      " 23%|██▎       | 27/119 [00:03<00:13,  6.85ba/s]\u001b[A\n",
      " 24%|██▎       | 28/119 [00:03<00:12,  7.41ba/s]\u001b[A\n",
      " 24%|██▍       | 29/119 [00:03<00:11,  7.82ba/s]\u001b[A\n",
      " 25%|██▌       | 30/119 [00:03<00:10,  8.17ba/s]\u001b[A\n",
      " 26%|██▌       | 31/119 [00:03<00:10,  8.26ba/s]\u001b[A\n",
      " 27%|██▋       | 32/119 [00:03<00:10,  8.48ba/s]\u001b[A\n",
      " 28%|██▊       | 33/119 [00:03<00:09,  8.71ba/s]\u001b[A\n",
      " 29%|██▊       | 34/119 [00:04<00:09,  8.78ba/s]\u001b[A\n",
      " 29%|██▉       | 35/119 [00:04<00:09,  8.80ba/s]\u001b[A\n",
      " 30%|███       | 36/119 [00:04<00:09,  8.58ba/s]\u001b[A\n",
      " 31%|███       | 37/119 [00:04<00:09,  8.50ba/s]\u001b[A\n",
      " 32%|███▏      | 38/119 [00:04<00:09,  8.69ba/s]\u001b[A\n",
      " 33%|███▎      | 39/119 [00:04<00:09,  8.82ba/s]\u001b[A\n",
      " 34%|███▎      | 40/119 [00:04<00:08,  8.86ba/s]\u001b[A\n",
      " 34%|███▍      | 41/119 [00:04<00:08,  8.81ba/s]\u001b[A\n",
      " 35%|███▌      | 42/119 [00:04<00:08,  8.85ba/s]\u001b[A\n",
      " 36%|███▌      | 43/119 [00:05<00:08,  8.98ba/s]\u001b[A\n",
      " 37%|███▋      | 44/119 [00:05<00:08,  8.88ba/s]\u001b[A\n",
      " 38%|███▊      | 45/119 [00:05<00:08,  8.98ba/s]\u001b[A\n",
      " 39%|███▊      | 46/119 [00:05<00:08,  9.05ba/s]\u001b[A\n",
      " 39%|███▉      | 47/119 [00:05<00:07,  9.05ba/s]\u001b[A\n",
      " 40%|████      | 48/119 [00:05<00:08,  8.66ba/s]\u001b[A\n",
      " 41%|████      | 49/119 [00:05<00:08,  8.63ba/s]\u001b[A\n",
      " 42%|████▏     | 50/119 [00:05<00:07,  8.77ba/s]\u001b[A\n",
      " 43%|████▎     | 51/119 [00:06<00:10,  6.26ba/s]\u001b[A\n",
      " 44%|████▎     | 52/119 [00:06<00:10,  6.41ba/s]\u001b[A\n",
      " 45%|████▍     | 53/119 [00:06<00:09,  6.80ba/s]\u001b[A\n",
      " 45%|████▌     | 54/119 [00:06<00:08,  7.26ba/s]\u001b[A\n",
      " 46%|████▌     | 55/119 [00:06<00:08,  7.62ba/s]\u001b[A\n",
      " 47%|████▋     | 56/119 [00:06<00:07,  7.99ba/s]\u001b[A\n",
      " 48%|████▊     | 57/119 [00:06<00:07,  8.21ba/s]\u001b[A\n",
      " 49%|████▊     | 58/119 [00:06<00:07,  8.44ba/s]\u001b[A\n",
      " 50%|████▉     | 59/119 [00:07<00:07,  8.48ba/s]\u001b[A\n",
      " 50%|█████     | 60/119 [00:07<00:07,  8.04ba/s]\u001b[A\n",
      " 51%|█████▏    | 61/119 [00:07<00:07,  8.03ba/s]\u001b[A\n",
      " 52%|█████▏    | 62/119 [00:07<00:06,  8.29ba/s]\u001b[A\n",
      " 53%|█████▎    | 63/119 [00:07<00:06,  8.44ba/s]\u001b[A\n",
      " 54%|█████▍    | 64/119 [00:07<00:06,  8.63ba/s]\u001b[A\n",
      " 55%|█████▍    | 65/119 [00:07<00:06,  8.63ba/s]\u001b[A\n",
      " 55%|█████▌    | 66/119 [00:07<00:06,  8.70ba/s]\u001b[A\n",
      " 56%|█████▋    | 67/119 [00:08<00:05,  8.74ba/s]\u001b[A\n",
      " 57%|█████▋    | 68/119 [00:08<00:05,  8.82ba/s]\u001b[A\n",
      " 58%|█████▊    | 69/119 [00:08<00:05,  8.88ba/s]\u001b[A\n",
      " 59%|█████▉    | 70/119 [00:08<00:05,  8.86ba/s]\u001b[A\n",
      " 60%|█████▉    | 71/119 [00:08<00:05,  8.87ba/s]\u001b[A\n",
      " 61%|██████    | 72/119 [00:08<00:05,  8.81ba/s]\u001b[A\n",
      " 61%|██████▏   | 73/119 [00:08<00:05,  8.85ba/s]\u001b[A\n",
      " 62%|██████▏   | 74/119 [00:08<00:05,  8.89ba/s]\u001b[A\n",
      " 63%|██████▎   | 75/119 [00:08<00:04,  8.89ba/s]\u001b[A\n",
      " 64%|██████▍   | 76/119 [00:09<00:06,  6.27ba/s]\u001b[A\n",
      " 65%|██████▍   | 77/119 [00:09<00:06,  6.43ba/s]\u001b[A\n",
      " 66%|██████▌   | 78/119 [00:09<00:05,  6.97ba/s]\u001b[A\n",
      " 66%|██████▋   | 79/119 [00:09<00:05,  7.55ba/s]\u001b[A\n",
      " 67%|██████▋   | 80/119 [00:09<00:04,  8.03ba/s]\u001b[A\n",
      " 68%|██████▊   | 81/119 [00:09<00:04,  8.45ba/s]\u001b[A\n",
      " 69%|██████▉   | 82/119 [00:09<00:04,  8.64ba/s]\u001b[A\n",
      " 70%|██████▉   | 83/119 [00:10<00:04,  8.71ba/s]\u001b[A\n",
      " 71%|███████   | 84/119 [00:10<00:03,  8.82ba/s]\u001b[A\n",
      " 71%|███████▏  | 85/119 [00:10<00:03,  8.91ba/s]\u001b[A\n",
      " 72%|███████▏  | 86/119 [00:10<00:03,  8.87ba/s]\u001b[A\n",
      " 73%|███████▎  | 87/119 [00:10<00:03,  8.98ba/s]\u001b[A\n",
      " 74%|███████▍  | 88/119 [00:10<00:03,  9.04ba/s]\u001b[A\n",
      " 75%|███████▍  | 89/119 [00:10<00:03,  9.05ba/s]\u001b[A\n",
      " 76%|███████▌  | 90/119 [00:10<00:03,  9.11ba/s]\u001b[A\n",
      " 76%|███████▋  | 91/119 [00:10<00:03,  9.13ba/s]\u001b[A\n",
      " 77%|███████▋  | 92/119 [00:11<00:02,  9.08ba/s]\u001b[A\n",
      " 78%|███████▊  | 93/119 [00:11<00:02,  8.96ba/s]\u001b[A\n",
      " 79%|███████▉  | 94/119 [00:11<00:02,  8.96ba/s]\u001b[A\n",
      " 80%|███████▉  | 95/119 [00:11<00:02,  9.00ba/s]\u001b[A\n",
      " 81%|████████  | 96/119 [00:11<00:02,  9.04ba/s]\u001b[A\n",
      " 82%|████████▏ | 97/119 [00:11<00:02,  9.08ba/s]\u001b[A\n",
      " 82%|████████▏ | 98/119 [00:11<00:02,  9.13ba/s]\u001b[A\n",
      " 83%|████████▎ | 99/119 [00:11<00:02,  9.17ba/s]\u001b[A\n",
      " 84%|████████▍ | 100/119 [00:11<00:02,  9.21ba/s]\u001b[A\n",
      " 85%|████████▍ | 101/119 [00:11<00:01,  9.30ba/s]\u001b[A\n",
      " 86%|████████▌ | 102/119 [00:12<00:01,  9.31ba/s]\u001b[A\n",
      " 87%|████████▋ | 103/119 [00:12<00:01,  9.31ba/s]\u001b[A\n",
      " 87%|████████▋ | 104/119 [00:12<00:01,  9.13ba/s]\u001b[A\n",
      " 88%|████████▊ | 105/119 [00:12<00:01,  9.05ba/s]\u001b[A\n",
      " 89%|████████▉ | 106/119 [00:12<00:01,  9.04ba/s]\u001b[A\n",
      " 90%|████████▉ | 107/119 [00:12<00:01,  6.35ba/s]\u001b[A\n",
      " 91%|█████████ | 108/119 [00:12<00:01,  6.63ba/s]\u001b[A\n",
      " 92%|█████████▏| 109/119 [00:13<00:01,  7.06ba/s]\u001b[A\n",
      " 92%|█████████▏| 110/119 [00:13<00:01,  7.55ba/s]\u001b[A\n",
      " 93%|█████████▎| 111/119 [00:13<00:01,  7.91ba/s]\u001b[A\n",
      " 94%|█████████▍| 112/119 [00:13<00:00,  8.22ba/s]\u001b[A\n",
      " 95%|█████████▍| 113/119 [00:13<00:00,  8.51ba/s]\u001b[A\n",
      " 96%|█████████▌| 114/119 [00:13<00:00,  8.62ba/s]\u001b[A\n",
      " 97%|█████████▋| 115/119 [00:13<00:00,  8.78ba/s]\u001b[A\n",
      " 97%|█████████▋| 116/119 [00:13<00:00,  8.86ba/s]\u001b[A\n",
      " 98%|█████████▊| 117/119 [00:13<00:00,  8.93ba/s]\u001b[A\n",
      "100%|██████████| 119/119 [00:14<00:00,  8.41ba/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-14 14:14:53,054][root][INFO] - Could not load query meta from /home/atsvigun/active_learning/examples/workdir/run_active_learning/2022-09-14/14-10-22_42_roberta_base_custom_strategy_least_confidence/query_meta.json: [Errno 2] No such file or directory: '/home/atsvigun/active_learning/examples/workdir/run_active_learning/2022-09-14/14-10-22_42_roberta_base_custom_strategy_least_confidence/query_meta.json'\n",
      "[2022-09-14 14:14:53,054][root][INFO] - Query meta: []\n",
      "[2022-09-14 14:14:53,054][root][INFO] - Dumping query meta to /home/atsvigun/active_learning/examples/workdir/run_active_learning/2022-09-14/14-10-22_42_roberta_base_custom_strategy_least_confidence/query_meta.json\n",
      "[2022-09-14 14:14:53,058][root][INFO] - ### Uncertainties of the queries ###\n",
      "[2022-09-14 14:14:53,058][root][INFO] - 0.66093, 0.64649, 0.64611, 0.64521, 0.64393, 0.64257, 0.62197, 0.62128, 0.61721, 0.61567, 0.61534, 0.60652, 0.60607, 0.60577, 0.6007, 0.60004, 0.59606, 0.58962, 0.5889, 0.58716, 0.58371, 0.58286, 0.58164, 0.57968, 0.57919, 0.57751, 0.57558, 0.57516, 0.57478, 0.57225, 0.57, 0.5687, 0.56471, 0.56262, 0.56101, 0.5601, 0.55933, 0.55555, 0.55176, 0.55163, 0.54784, 0.54709, 0.54604, 0.54514, 0.54357, 0.54294, 0.5412, 0.54081, 0.53829, 0.53819, 0.53764, 0.53674, 0.53618, 0.53583, 0.53544, 0.53313, 0.53196, 0.53182, 0.52962, 0.52885, 0.52611, 0.52603, 0.52535, 0.52443, 0.52384, 0.52299, 0.52284, 0.52278, 0.5222, 0.52193, 0.52154, 0.52042, 0.52017, 0.51958, 0.51912, 0.51853, 0.51727, 0.51727, 0.51634, 0.51623, 0.51571, 0.51531, 0.51513, 0.51427, 0.51381, 0.51264, 0.5122, 0.51187, 0.51134, 0.51128, 0.51119, 0.51033, 0.50976, 0.50938, 0.50879, 0.50876, 0.50845, 0.50815, 0.50752, 0.50621, 0.506, 0.50583, 0.50578, 0.50568, 0.50554, 0.50494, 0.50424, 0.5026, 0.50238, 0.50229, 0.50194, 0.50177, 0.50172, 0.50151, 0.5015, 0.50119, 0.50115, 0.50114, 0.50103, 0.50093, 0.50068, 0.50065, 0.50059, 0.50049, 0.50043, 0.49925, 0.49925, 0.49917, 0.49904, 0.49871, 0.49865, 0.49854, 0.49841, 0.49825, 0.49773, 0.49773, 0.49721, 0.4971, 0.49703, 0.49701, 0.49678, 0.49671, 0.49648, 0.49621, 0.49619, 0.49616, 0.49581, 0.49557, 0.49551, 0.4955, 0.49541, 0.49523, 0.49491, 0.49471, 0.49453, 0.49414, 0.49387, 0.49351, 0.49349, 0.4933, 0.49327, 0.49323, 0.49313, 0.49281, 0.49273, 0.49251, 0.49215, 0.49214, 0.49204, 0.49198, 0.49191, 0.49184, 0.49178, 0.49168, 0.49164, 0.49142, 0.49129, 0.49107, 0.49105, 0.49104, 0.49099, 0.49073, 0.49064, 0.49045, 0.49043, 0.49036, 0.49028, 0.49028, 0.49026, 0.49023, 0.49006, 0.48953, 0.4893, 0.4892, 0.48915, 0.48913, 0.48902, 0.4889, 0.48861, 0.48845, 0.48835, 0.48834, 0.48833, 0.48822, 0.48805, 0.48802, 0.48798, 0.48769, 0.48767, 0.48763, 0.4872, 0.48714, 0.48696, 0.4869, 0.48679, 0.48675, 0.48666, 0.48654, 0.48648, 0.48615, 0.48598, 0.4858, 0.48545, 0.4854, 0.48465, 0.48452, 0.4844, 0.48431, 0.48424, 0.4842, 0.48406, 0.48404, 0.48403, 0.48403, 0.48393, 0.48368, 0.48358, 0.48312, 0.48298, 0.48286, 0.48274, 0.48266, 0.48264, 0.48247, 0.48244, 0.48221, 0.48197, 0.48178, 0.48155, 0.48147, 0.48105, 0.48087, 0.48082, 0.48073, 0.48068, 0.48064, 0.48051, 0.48046, 0.48033, 0.48001, 0.47998, 0.47969, 0.47964, 0.47962, 0.47937, 0.47916, 0.47897, 0.47893, 0.4789, 0.47836, 0.47829, 0.47762, 0.47761, 0.47746, 0.4774, 0.47715, 0.47711, 0.47696, 0.47673, 0.47668, 0.47636, 0.47613, 0.47605, 0.47603, 0.4753, 0.47517, 0.47513, 0.47503, 0.47501, 0.47482, 0.47475, 0.47459, 0.47447, 0.47446, 0.47421, 0.47402, 0.47381, 0.47369, 0.47348, 0.47347, 0.47332, 0.47327, 0.47326, 0.47303, 0.47302, 0.47299, 0.47287, 0.47265, 0.47257, 0.47252, 0.47242, 0.47205, 0.47194, 0.47151, 0.47134, 0.47126, 0.47093, 0.4707, 0.47066, 0.47049, 0.47041, 0.4701, 0.46993, 0.46962, 0.46863, 0.46858, 0.46839, 0.46836, 0.46835, 0.46827, 0.4681, 0.46791, 0.46789, 0.46788, 0.4678, 0.46761, 0.46753, 0.46726, 0.46696, 0.46694, 0.46675, 0.46675, 0.46665, 0.46659, 0.46658, 0.46645, 0.46641, 0.46637, 0.46608, 0.46598, 0.46575, 0.46574, 0.46544, 0.46538, 0.46537, 0.46523, 0.46522, 0.46508, 0.46503, 0.46499, 0.46488, 0.4648, 0.46476, 0.46473, 0.46428, 0.46379, 0.46377, 0.46354, 0.4632, 0.46313, 0.46307, 0.46295, 0.46284, 0.46274, 0.46257, 0.46226, 0.46208, 0.4613, 0.46125, 0.46099, 0.46072, 0.4606, 0.46043, 0.46022, 0.46018, 0.46007, 0.45995, 0.45946, 0.45896, 0.4589, 0.45874, 0.45871, 0.45861, 0.45845, 0.45843, 0.45827, 0.45824, 0.45818, 0.45788, 0.45786, 0.45777, 0.45754, 0.45752, 0.4575, 0.45741, 0.45717, 0.45699, 0.45662, 0.45648, 0.45648, 0.45637, 0.45621, 0.45572, 0.45525, 0.4552, 0.45505, 0.45498, 0.45467, 0.4546, 0.45394, 0.4535, 0.45346, 0.45335, 0.45331, 0.453, 0.45279, 0.452, 0.4519, 0.45178, 0.4516, 0.45142, 0.45127, 0.45113, 0.45107, 0.45104, 0.45092, 0.45089, 0.45082, 0.4504, 0.45033, 0.45029, 0.45027, 0.44997, 0.44981, 0.44945, 0.44931, 0.44919, 0.44917, 0.44895, 0.44875, 0.44839, 0.44819, 0.44813, 0.44773, 0.44739, 0.44738, 0.44728, 0.44677, 0.4467, 0.44626, 0.44621, 0.44603, 0.44602, 0.44591, 0.44578, 0.44558, 0.44524, 0.44515, 0.44509, 0.44467, 0.44448, 0.44433, 0.44428, 0.44408, 0.44387, 0.44364, 0.44349, 0.44332, 0.44309, 0.44295, 0.44197, 0.44185, 0.4418, 0.44152, 0.44145, 0.44129, 0.44116, 0.44105, 0.4408, 0.44066, 0.44056, 0.43998, 0.4399, 0.43984, 0.43938, 0.43936, 0.43917, 0.43908, 0.43901, 0.43845, 0.4383, 0.43822, 0.4382, 0.43813, 0.4381, 0.43805, 0.43786, 0.43784, 0.43763, 0.43723, 0.43715, 0.43698, 0.43691, 0.4369, 0.43688, 0.43666, 0.43659, 0.43633, 0.43581, 0.43555, 0.4355, 0.43531, 0.43526, 0.43519, 0.43514, 0.43482, 0.43479, 0.43477, 0.43476, 0.43468, 0.43461, 0.43438, 0.43433, 0.43429, 0.4342, 0.4341, 0.43409, 0.43408, 0.43406, 0.43398, 0.43388, 0.43365, 0.43357, 0.43356, 0.43339, 0.43335, 0.4331, 0.43284, 0.4327, 0.43269, 0.43267, 0.43258, 0.43257, 0.43231, 0.43205, 0.43197, 0.43171, 0.43168, 0.43143, 0.43136, 0.43127, 0.431, 0.43072, 0.43068, 0.43053, 0.4304, 0.43021, 0.43011, 0.4301, 0.42941, 0.42938, 0.42865, 0.42856, 0.42846, 0.42844, 0.4279, 0.42756, 0.42725, 0.42699, 0.42696, 0.42693, 0.42691, 0.42675, 0.42659, 0.42658, 0.42637, 0.4261, 0.42591, 0.42574, 0.4256, 0.42537, 0.42535, 0.4253, 0.42522, 0.42479, 0.42445, 0.42437, 0.42427, 0.42405, 0.42399, 0.42367, 0.42365, 0.42348, 0.42334, 0.42333, 0.4231, 0.4231, 0.42294, 0.42287, 0.42283, 0.42279, 0.42265, 0.42224, 0.42193, 0.42185, 0.42171, 0.42164, 0.42163, 0.42156, 0.42146, 0.42143, 0.42135, 0.42132, 0.42112, 0.4207, 0.42049, 0.42002, 0.42001, 0.41993, 0.41985, 0.41975, 0.41949, 0.41929, 0.41916, 0.41914, 0.4191, 0.41893, 0.41865, 0.41844, 0.41785, 0.4178, 0.41768, 0.41753, 0.41733, 0.41719, 0.41705, 0.41705, 0.4168, 0.41679, 0.41668, 0.4166, 0.41658, 0.41636, 0.41635, 0.41625, 0.41601, 0.41582, 0.41564, 0.41561, 0.41519, 0.41495, 0.41492, 0.41485, 0.41482, 0.41452, 0.41447, 0.41433, 0.41422, 0.41408, 0.41384, 0.41362, 0.4136, 0.41336, 0.41331, 0.41327, 0.41306, 0.41304, 0.41288, 0.41251, 0.41236, 0.41226, 0.41222, 0.41207, 0.41206, 0.41149, 0.41143, 0.41142, 0.4114, 0.41102, 0.411, 0.41074, 0.4106, 0.41051, 0.41044, 0.40998, 0.40997, 0.40992, 0.40988, 0.40976, 0.40962, 0.4095, 0.40932, 0.40929, 0.40929, 0.40928, 0.4092, 0.40919, 0.40894, 0.40892, 0.40879, 0.40875, 0.40865, 0.40864, 0.40861, 0.4086, 0.40824, 0.40822, 0.40817, 0.40816, 0.40803, 0.408, 0.40794, 0.40792, 0.40766, 0.40757, 0.40749, 0.40748, 0.40712, 0.40707, 0.40684, 0.40668, 0.40663, 0.40655, 0.40651, 0.40635, 0.40632, 0.40629, 0.40616, 0.40589, 0.40571, 0.40562, 0.40555, 0.40553, 0.40551, 0.40518, 0.40512, 0.40504, 0.40499, 0.40476, 0.40461, 0.40441, 0.40413, 0.40385, 0.40348, 0.40332, 0.40324, 0.40311, 0.40298, 0.40287, 0.40284, 0.40283, 0.40207, 0.40177, 0.40173, 0.40169, 0.40148, 0.40097, 0.40095, 0.40075, 0.40054, 0.40042, 0.40025, 0.40024, 0.40012, 0.40003, 0.3997, 0.39962, 0.39943, 0.39907, 0.39905, 0.39903, 0.39893, 0.39883, 0.39861, 0.39825, 0.39822, 0.39814, 0.39806, 0.39796, 0.39745, 0.39733, 0.39728, 0.39715, 0.39695, 0.39688, 0.39681, 0.39678, 0.39666, 0.39654, 0.39651, 0.39614, 0.39601, 0.396, 0.39577, 0.39551, 0.39549, 0.39486, 0.3946, 0.39422, 0.39403, 0.39403, 0.39388, 0.39378, 0.39373, 0.39359, 0.39359, 0.39351, 0.39339, 0.39334, 0.39332, 0.39327, 0.39307, 0.39283, 0.39273, 0.39267, 0.39257, 0.39216, 0.39208, 0.39206, 0.3919, 0.39153, 0.39146, 0.39126, 0.39099, 0.3909, 0.39087, 0.39082, 0.39079, 0.39077, 0.39072, 0.39064, 0.39026, 0.3901, 0.39, 0.38978, 0.3896, 0.38909, 0.38907, 0.38871, 0.3887, 0.38833, 0.38787, 0.38787, 0.38775, 0.38767, 0.3874, 0.3872, 0.38647, 0.3864, 0.38618, 0.38602, 0.38564, 0.38551, 0.3852, 0.38512, 0.38471, 0.38457, 0.38456, 0.38456, 0.38437, 0.38415, 0.38397, 0.38394, 0.38384, 0.38361, 0.38354, 0.38352, 0.3835, 0.3832, 0.3831, 0.38281, 0.38217, 0.38195, 0.38185, 0.38185, 0.38157, 0.38155, 0.38146, 0.38122, 0.38109, 0.38104, 0.38095, 0.38078, 0.38078, 0.38074, 0.38065, 0.38061, 0.3806, 0.38029, 0.37971, 0.37969, 0.37916, 0.37905, 0.37899, 0.37892, 0.37872, 0.37836, 0.37827, 0.37795, 0.37795, 0.37763, 0.3776, 0.37756, 0.3775, 0.37709, 0.37697, 0.37691, 0.37683, 0.37643, 0.37639, 0.37611, 0.37592, 0.37586, 0.37575, 0.37555, 0.37551, 0.37547, 0.37537, 0.37533, 0.37517, 0.37501, 0.37468, 0.37455, 0.37444, 0.37425, 0.37416, 0.37412, 0.37398, 0.37389, 0.37374, 0.37329, 0.37313, 0.37306, 0.37271, 0.3727, 0.37265, 0.3726, 0.3725, 0.37248, 0.37233, 0.37232, 0.37172, 0.37163, 0.37153, 0.37131, 0.37118, 0.37105, 0.37103, 0.37087, 0.3708, 0.37067, 0.37057, 0.37043, 0.37042, 0.37042, 0.37009, 0.36934, 0.36934, 0.36886, 0.36878, 0.36864, 0.3686, 0.36859, 0.36857, 0.36856, 0.3681, 0.36808, 0.36807, 0.36802, 0.368, 0.36789, 0.36784, 0.36733, 0.36698, 0.36696, 0.36687, 0.36647, 0.36621, 0.36606, 0.36589, 0.36575, 0.36557, 0.36539, 0.36539, 0.36531, 0.3652, 0.36514, 0.36506, 0.36489, 0.36485, 0.36466, 0.36441, 0.36438, 0.36393, 0.36367, 0.36357, 0.36345, 0.36336, 0.36293, 0.36289, 0.36273, 0.36265, 0.36245, 0.36239, 0.36234, 0.36234, 0.36226, 0.36216, 0.36188, 0.36183, 0.36164, 0.36154, 0.36141, 0.36137, 0.36134, 0.36129, 0.36128, 0.36108, 0.36045, 0.36032, 0.36026, 0.36018, 0.35999, 0.35995, 0.35977, 0.35969, 0.35947, 0.35905, 0.35878, 0.3586, 0.35857, 0.35856, 0.35822, 0.35764, 0.35759, 0.35738, 0.35722, 0.35719, 0.35665, 0.35661, 0.35637, 0.35585, 0.35546, 0.35518, 0.35503, 0.3548, 0.35439, 0.35389, 0.35389, 0.3537, 0.3536, 0.35341, 0.35312, 0.35295, 0.35284, 0.35282, 0.35256, 0.3523, 0.35229, 0.35196, 0.35173, 0.35162, 0.3516, 0.35146, 0.35131, 0.35128, 0.3509, 0.35059, 0.35044, 0.35025, 0.34974, 0.34967, 0.34964, 0.34933, 0.34916, 0.349, 0.34899, 0.34895, 0.34887, 0.34851, 0.34818, 0.3481, 0.34779, 0.34773, 0.34771, 0.34761, 0.34759, 0.34757, 0.34756, 0.3474, 0.3473, 0.34715, 0.34709, 0.34704, 0.34695, 0.34694, 0.34692, 0.3469, 0.34626, 0.34623, 0.34617, 0.34601, 0.34586, 0.3457, 0.34566, 0.34557, 0.34552, 0.34539, 0.34536, 0.34512, 0.3449, 0.34459, 0.34457, 0.34446, 0.34409, 0.34408, 0.34392, 0.34384, 0.3438, 0.34373, 0.34363, 0.34321, 0.3432, 0.34297, 0.3429, 0.34229, 0.34183, 0.34169, 0.34166, 0.3414, 0.34139, 0.34138, 0.34138, 0.34136, 0.3413, 0.34129, 0.34122, 0.34119, 0.3411, 0.3411, 0.34104, 0.34078, 0.34067, 0.34052, 0.34045, 0.34007, 0.33991, 0.33986, 0.33983, 0.33975, 0.33968, 0.3396, 0.33949, 0.33945, 0.33921, 0.33899, 0.33873, 0.33861, 0.33859, 0.33858, 0.33856, 0.33841, 0.33835, 0.33826, 0.3382, 0.33756, 0.33749, 0.3374, 0.33696, 0.33683, 0.33659, 0.33657, 0.33639, 0.33638, 0.33624, 0.33597, 0.33565, 0.33511, 0.33503, 0.33495, 0.33484, 0.33477, 0.33468, 0.33455, 0.33452, 0.33441, 0.33437, 0.33415, 0.33409, 0.33404\n",
      "[2022-09-14 14:14:53,059][root][INFO] - ############### Evaluating the query by the acquisition model. ###############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?ba/s]\u001b[A\n",
      "100%|██████████| 2/2 [00:00<00:00, 11.25ba/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-14 14:14:54,541][root][INFO] - AL iteration 1:\n",
      "Acquisition_Evaluate_Query model:\n",
      "[2022-09-14 14:14:54,543][root][INFO] - test_loss: 1.1151825189590454\n",
      "[2022-09-14 14:14:54,543][root][INFO] - test_accuracy: 0.44083333333333335\n",
      "[2022-09-14 14:14:54,543][root][INFO] - test_f1_micro: 0.44083333333333335\n",
      "[2022-09-14 14:14:54,543][root][INFO] - test_f1_macro: 0.4222768305283723\n",
      "[2022-09-14 14:14:54,543][root][INFO] - test_f1_weighted: 0.4523392182981729\n",
      "[2022-09-14 14:14:54,543][root][INFO] - test_runtime: 1.1288\n",
      "[2022-09-14 14:14:54,543][root][INFO] - test_samples_per_second: 1063.107\n",
      "[2022-09-14 14:14:54,543][root][INFO] - test_steps_per_second: 10.631\n",
      "[2022-09-14 14:14:54,554][root][INFO] - Training dataset size: 2400\n",
      "[2022-09-14 14:14:54,554][root][INFO] - Validation dataset size: 7600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/3 [00:00<?, ?ba/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:00<00:00,  6.53ba/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:00<00:00,  9.41ba/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-14 14:15:03,136][root][INFO] - Load best at end: False\n",
      "[2022-09-14 14:15:03,140][root][INFO] - TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=True,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=True,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=40,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=./output/roberta_base_42_2022-09-14_14-10-22/acquisition/runs/Sep14_14-15-03_cn-012,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=no,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=eval_accuracy,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=10,\n",
      "optim=adamw_hf,\n",
      "output_dir=./output/roberta_base_42_2022-09-14_14-10-22/acquisition,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=100,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=./output/roberta_base_42_2022-09-14_14-10-22/acquisition,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.1,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.01,\n",
      "xpu_backend=None,\n",
      ")\n",
      "[2022-09-14 14:15:05,827][root][INFO] - Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atsvigun/anaconda3/envs/al/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-14 14:17:53,845][root][INFO] - Done with the model fit.\n",
      "[2022-09-14 14:17:53,857][root][INFO] - ############### Evaluating the acquisition model. ###############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/8 [00:00<?, ?ba/s]\u001b[A\n",
      " 12%|█▎        | 1/8 [00:00<00:01,  5.82ba/s]\u001b[A\n",
      " 25%|██▌       | 2/8 [00:00<00:00,  7.39ba/s]\u001b[A\n",
      " 38%|███▊      | 3/8 [00:00<00:00,  8.29ba/s]\u001b[A\n",
      " 50%|█████     | 4/8 [00:00<00:00,  8.74ba/s]\u001b[A\n",
      " 62%|██████▎   | 5/8 [00:00<00:00,  9.08ba/s]\u001b[A\n",
      " 75%|███████▌  | 6/8 [00:00<00:00,  9.34ba/s]\u001b[A\n",
      "100%|██████████| 8/8 [00:00<00:00,  9.35ba/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-14 14:18:02,011][root][INFO] - AL iteration 1:\n",
      "Acquisition model:\n",
      "[2022-09-14 14:18:02,015][root][INFO] - test_loss: 0.5024663209915161\n",
      "[2022-09-14 14:18:02,017][root][INFO] - test_accuracy: 0.9232894736842105\n",
      "[2022-09-14 14:18:02,018][root][INFO] - test_f1_micro: 0.9232894736842105\n",
      "[2022-09-14 14:18:02,018][root][INFO] - test_f1_macro: 0.923027730225176\n",
      "[2022-09-14 14:18:02,019][root][INFO] - test_f1_weighted: 0.923027730225176\n",
      "[2022-09-14 14:18:02,019][root][INFO] - test_runtime: 7.0611\n",
      "[2022-09-14 14:18:02,019][root][INFO] - test_samples_per_second: 1076.32\n",
      "[2022-09-14 14:18:02,019][root][INFO] - test_steps_per_second: 10.763\n",
      "[2022-09-14 14:18:02,100][root][INFO] - =================AL iteration #2 started.=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AL queries done:   7%|▋         | 1/15 [05:09<1:12:08, 309.17s/it]\n",
      "  0%|          | 0/118 [00:00<?, ?ba/s]\u001b[A\n",
      "  1%|          | 1/118 [00:00<00:18,  6.23ba/s]\u001b[A\n",
      "  2%|▏         | 2/118 [00:00<00:16,  7.03ba/s]\u001b[A\n",
      "  3%|▎         | 3/118 [00:00<00:14,  7.76ba/s]\u001b[A\n",
      "  3%|▎         | 4/118 [00:00<00:13,  8.17ba/s]\u001b[A\n",
      "  4%|▍         | 5/118 [00:00<00:13,  8.43ba/s]\u001b[A\n",
      "  5%|▌         | 6/118 [00:00<00:13,  8.55ba/s]\u001b[A\n",
      "  6%|▌         | 7/118 [00:00<00:12,  8.75ba/s]\u001b[A\n",
      "  7%|▋         | 8/118 [00:00<00:12,  8.87ba/s]\u001b[A\n",
      "  8%|▊         | 9/118 [00:01<00:12,  8.95ba/s]\u001b[A\n",
      "  8%|▊         | 10/118 [00:01<00:11,  9.04ba/s]\u001b[A\n",
      "  9%|▉         | 11/118 [00:01<00:11,  9.03ba/s]\u001b[A\n",
      " 10%|█         | 12/118 [00:01<00:11,  9.10ba/s]\u001b[A\n",
      " 11%|█         | 13/118 [00:01<00:11,  9.03ba/s]\u001b[A\n",
      " 12%|█▏        | 14/118 [00:01<00:11,  9.04ba/s]\u001b[A\n",
      " 13%|█▎        | 15/118 [00:01<00:11,  9.12ba/s]\u001b[A\n",
      " 14%|█▎        | 16/118 [00:01<00:11,  9.13ba/s]\u001b[A\n",
      " 14%|█▍        | 17/118 [00:01<00:10,  9.19ba/s]\u001b[A\n",
      " 15%|█▌        | 18/118 [00:02<00:10,  9.14ba/s]\u001b[A\n",
      " 16%|█▌        | 19/118 [00:02<00:10,  9.03ba/s]\u001b[A\n",
      " 17%|█▋        | 20/118 [00:02<00:10,  9.07ba/s]\u001b[A\n",
      " 18%|█▊        | 21/118 [00:02<00:10,  9.11ba/s]\u001b[A\n",
      " 19%|█▊        | 22/118 [00:02<00:10,  9.16ba/s]\u001b[A\n",
      " 19%|█▉        | 23/118 [00:02<00:10,  9.14ba/s]\u001b[A\n",
      " 20%|██        | 24/118 [00:02<00:10,  9.17ba/s]\u001b[A\n",
      " 21%|██        | 25/118 [00:02<00:10,  9.16ba/s]\u001b[A\n",
      " 22%|██▏       | 26/118 [00:02<00:10,  9.19ba/s]\u001b[A\n",
      " 23%|██▎       | 27/118 [00:03<00:09,  9.26ba/s]\u001b[A\n",
      " 24%|██▎       | 28/118 [00:03<00:09,  9.19ba/s]\u001b[A\n",
      " 25%|██▍       | 29/118 [00:03<00:12,  6.95ba/s]\u001b[A\n",
      " 25%|██▌       | 30/118 [00:03<00:11,  7.43ba/s]\u001b[A\n",
      " 26%|██▋       | 31/118 [00:03<00:11,  7.77ba/s]\u001b[A\n",
      " 27%|██▋       | 32/118 [00:03<00:10,  8.11ba/s]\u001b[A\n",
      " 28%|██▊       | 33/118 [00:03<00:10,  8.44ba/s]\u001b[A\n",
      " 29%|██▉       | 34/118 [00:03<00:09,  8.67ba/s]\u001b[A\n",
      " 30%|██▉       | 35/118 [00:04<00:09,  8.78ba/s]\u001b[A\n",
      " 31%|███       | 36/118 [00:04<00:09,  8.90ba/s]\u001b[A\n",
      " 31%|███▏      | 37/118 [00:04<00:09,  8.92ba/s]\u001b[A\n",
      " 32%|███▏      | 38/118 [00:04<00:08,  8.95ba/s]\u001b[A\n",
      " 33%|███▎      | 39/118 [00:04<00:08,  9.03ba/s]\u001b[A\n",
      " 34%|███▍      | 40/118 [00:04<00:08,  9.07ba/s]\u001b[A\n",
      " 35%|███▍      | 41/118 [00:04<00:08,  9.03ba/s]\u001b[A\n",
      " 36%|███▌      | 42/118 [00:04<00:08,  9.04ba/s]\u001b[A\n",
      " 36%|███▋      | 43/118 [00:04<00:08,  9.03ba/s]\u001b[A\n",
      " 37%|███▋      | 44/118 [00:05<00:08,  8.59ba/s]\u001b[A\n",
      "AL queries done:   7%|▋         | 1/15 [05:14<1:13:21, 314.36s/it]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/atsvigun/active_learning/examples/../scripts/run_active_learning.py\", line 137, in <module>\n",
      "    main()\n",
      "  File \"/home/atsvigun/anaconda3/envs/al/lib/python3.9/site-packages/hydra/main.py\", line 49, in decorated_main\n",
      "    _run_hydra(\n",
      "  File \"/home/atsvigun/anaconda3/envs/al/lib/python3.9/site-packages/hydra/_internal/utils.py\", line 367, in _run_hydra\n",
      "    run_and_report(\n",
      "  File \"/home/atsvigun/anaconda3/envs/al/lib/python3.9/site-packages/hydra/_internal/utils.py\", line 211, in run_and_report\n",
      "    return func()\n",
      "  File \"/home/atsvigun/anaconda3/envs/al/lib/python3.9/site-packages/hydra/_internal/utils.py\", line 368, in <lambda>\n",
      "    lambda: hydra.run(\n",
      "  File \"/home/atsvigun/anaconda3/envs/al/lib/python3.9/site-packages/hydra/_internal/hydra.py\", line 97, in run\n",
      "    ret = run_job(\n",
      "  File \"/home/atsvigun/anaconda3/envs/al/lib/python3.9/site-packages/hydra/core/utils.py\", line 160, in run_job\n",
      "    ret.return_value = task_function(task_cfg)\n",
      "  File \"/home/atsvigun/active_learning/examples/../scripts/run_active_learning.py\", line 133, in main\n",
      "    run_active_learning(config)\n",
      "  File \"/home/atsvigun/active_learning/acleto/al4nlp/utils/main_decorator.py\", line 36, in run_script\n",
      "    func(config, work_dir=Path(auto_generated_dir))\n",
      "  File \"/home/atsvigun/active_learning/examples/../scripts/run_active_learning.py\", line 110, in run_active_learning\n",
      "    models = al_loop(\n",
      "  File \"/home/atsvigun/active_learning/acleto/al_benchmark/simulated_active_learning.py\", line 677, in al_loop\n",
      "    ) = learner.query(unlabeled_data, n_instances=num_query_instances_or_tokens)\n",
      "  File \"/home/atsvigun/active_learning/acleto/al4nlp/active_learner.py\", line 52, in query\n",
      "    output = self.query_strategy(\n",
      "  File \"custom_strategy/least_confidence.py\", line 5, in least_confidence\n",
      "    probas = model.predict_proba(X_pool)\n",
      "  File \"/home/atsvigun/active_learning/acleto/al4nlp/model_wrappers/transformers/wrapper_encoder.py\", line 233, in predict_proba\n",
      "    logits = self.predict_logits(\n",
      "  File \"/home/atsvigun/active_learning/acleto/al4nlp/model_wrappers/transformers/wrapper_encoder.py\", line 219, in predict_logits\n",
      "    predictions = self.get_predictions(data, **kwargs)\n",
      "  File \"/home/atsvigun/active_learning/acleto/al4nlp/model_wrappers/transformers/wrapper_encoder.py\", line 164, in get_predictions\n",
      "    data = self.tokenize_data(\n",
      "  File \"/home/atsvigun/active_learning/acleto/al4nlp/model_wrappers/transformers/transformers_base_wrapper.py\", line 363, in tokenize_data\n",
      "    return data.map(\n",
      "  File \"/home/atsvigun/anaconda3/envs/al/lib/python3.9/site-packages/datasets/arrow_dataset.py\", line 2387, in map\n",
      "    return self._map_single(\n",
      "  File \"/home/atsvigun/anaconda3/envs/al/lib/python3.9/site-packages/datasets/arrow_dataset.py\", line 557, in wrapper\n",
      "    out: Union[\"Dataset\", \"DatasetDict\"] = func(self, *args, **kwargs)\n",
      "  File \"/home/atsvigun/anaconda3/envs/al/lib/python3.9/site-packages/datasets/arrow_dataset.py\", line 524, in wrapper\n",
      "    out: Union[\"Dataset\", \"DatasetDict\"] = func(self, *args, **kwargs)\n",
      "  File \"/home/atsvigun/anaconda3/envs/al/lib/python3.9/site-packages/datasets/fingerprint.py\", line 480, in wrapper\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error while terminating subprocess (pid=14253): \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "CUDA_VISIBLE_DEVICES='0' HYDRA_CONFIG_PATH=../acleto/al_benchmark/configs \\\n",
    "HYDRA_CONFIG_NAME=al_cls python ../scripts/run_active_learning.py \\\n",
    "al.strategy=custom_strategy/least_confidence \\\n",
    "al.sampling_type=custom_strategy/top_from_previous_iteration_subsampling \\\n",
    "acquisition_model.checkpoint=distilbert-base-uncased \\\n",
    "al.num_queries=2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c0b8aa-b8e5-4290-9395-426826bda25d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The results will be located in the file `workdir/run_active_learning/TODAY_DATE/TIME_SEED_MODEL/acquisition_metrics.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d09cb3f-40b2-408f-a67f-fd6b90e0ec38",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [anaconda3-al]",
   "language": "python",
   "name": "conda-env-anaconda3-al-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
